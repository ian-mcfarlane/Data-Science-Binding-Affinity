{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import csv\n",
    "import sqlite3\n",
    "from pathlib import Path\n",
    "import rdkit\n",
    "\n",
    "from rdkit import Chem, DataStructs\n",
    "from rdkit.Chem.Fingerprints import FingerprintMols\n",
    "from rdkit.Chem import Lipinski\n",
    "from rdkit.Chem import Descriptors\n",
    "from rdkit.Chem import Crippen\n",
    "from pathlib import Path\n",
    "from dbManager import DatabaseManager\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "all_data_file = Path('activity_data.csv')\n",
    "\n",
    "manager = DatabaseManager(database_path='activity_data.db')\n",
    "manager.drop_all()\n",
    "manager.create()\n",
    "manager.populate_compounds_table(all_data_file=all_data_file)\n",
    "manager.populate_assays_table(all_data_file=all_data_file)\n",
    "\n",
    "\n",
    "manager.get_conn().commit()\n",
    "\n",
    "df = pd.read_sql_query(\"SELECT CID, smiles from compounds\", manager.get_conn())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['fingerprint'] = df.smiles.apply(lambda x : AllChem.GetMorganFingerprint(m1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1024\n",
      "1024\n",
      "1024\n",
      "512\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "512\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "512\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "512\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "1024\n",
      "256\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "512\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "512\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "512\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "256\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "512\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "512\n",
      "1024\n",
      "1024\n",
      "512\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "512\n",
      "512\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "512\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "512\n",
      "512\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n"
     ]
    }
   ],
   "source": [
    "for item in df.fingerprint.tolist():\n",
    "    item = np.array(item)\n",
    "    if item.size != 2048:\n",
    "        print(item.size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cluster by Tanimoto similarity \n",
    "Alows for horizontal splits of data into "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute fingerprint\n",
    "df['fingerprint'] = df.smiles.apply(lambda x : FingerprintMols.FingerprintMol(Chem.MolFromSmiles(x)))\n",
    "#Define clustering setup\n",
    "def ClusterFps(fps,cutoff=0.2):\n",
    "    from rdkit import DataStructs\n",
    "    from rdkit.ML.Cluster import Butina\n",
    "\n",
    "    # first generate the distance matrix:\n",
    "    dists = []\n",
    "    nfps = len(fps)\n",
    "    for i in range(1,nfps):\n",
    "        sims = DataStructs.BulkTanimotoSimilarity(fps[i],fps[:i])\n",
    "        dists.extend([1-x for x in sims])\n",
    "\n",
    "    # now cluster the data:\n",
    "    cs = Butina.ClusterData(dists,nfps,cutoff,isDistData=True)\n",
    "    return cs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering\n",
    "Investigating the effect of cutoff on number of clusters generated.\n",
    "Using Butina clustering.\n",
    "Will use a cutoff of 0.5 which gives 32 clusters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoffs = [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]\n",
    "cutoff_clusters = []\n",
    "for cutoff in cutoffs:\n",
    "    cutoff_clusters.append(ClusterFps(df.fingerprint.tolist(), cutoff=cutoff))\n",
    "n_clusters = list(len(x) for x in cutoff_clusters)\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(cutoffs,n_clusters)\n",
    "print(n_clusters)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters_0_4 = cutoff_clusters[3]\n",
    "def find_cluster(clusters, item):\n",
    "    for i, cluster in enumerate(clusters):\n",
    "        if item in cluster:\n",
    "            return i\n",
    "# write cluster number of pandas df\n",
    "df['clusters'] =  df.index.map(lambda x : find_cluster(clusters_0_4, x))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training split\n",
    "Use a horizontal split to create train and test using 80/20 split.\n",
    "Randomly allocate clusters to test until >20%. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "408 407.40000000000003\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "target_test_size = len(df) * 0.2\n",
    "test_size = 0\n",
    "test_clusters = []\n",
    "# not include first cluster\n",
    "cluster_sizes = dict(df.clusters.value_counts())\n",
    "while test_size < target_test_size:\n",
    "    random_cluster = random.choice(list(cluster_sizes.keys()))\n",
    "    size = cluster_sizes.pop(random_cluster)\n",
    "    test_clusters.append(random_cluster)\n",
    "    test_size += size\n",
    "print(test_size, target_test_size)\n",
    "df['test'] = df.clusters.apply(lambda x: True if x in test_clusters else False)\n",
    "df.to_pickle('pandas_dumps/compounds_split.pkl')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_p"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3546a01ffcde53547cbaba027003f82af07a8279fa2f60bb0ef7a029d6660063"
  },
  "kernelspec": {
   "display_name": "Python 3.7.9 64-bit ('cheminformatics': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
